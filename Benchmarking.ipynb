{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR   = os.path.join(os.getcwd(), \"data\")\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), \"output\")\n",
    "\n",
    "# Utility functions\n",
    "Path     = os.path.join\n",
    "DataPath = lambda path: os.path.join(DATA_DIR, path)\n",
    "\n",
    "def mkdir_p(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        Path(DATA_DIR, 'verified'),\n",
    "        color_mode='rgb',\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    ")\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "        Path(DATA_DIR, 'verified'),\n",
    "        color_mode='rgb',\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    ")\n",
    "\n",
    "# Split using https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "print(\"Label codes : \", train_generator.class_indices)\n",
    "print(\"Training data   : \", train_generator.n)\n",
    "print(\"Validation data : \", valid_generator.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(img_width, img_height, 3))\n",
    "# model.summary()\n",
    "top_model = Sequential([\n",
    "    Flatten(input_shape=model.output_shape[1:]),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "seq = Sequential([model, top_model])\n",
    "# Compile with Binary Crossentropy loss and SGD optimizer\n",
    "seq.compile(loss='categorical_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.9), metrics=['accuracy'])\n",
    "# Train for 5 epochs\n",
    "seq.fit_generator(train_generator, epochs=5, validation_data=valid_generator)\n",
    "\n",
    "output = seq.predict_generator(test_generator)\n",
    "fids = map(lambda x: os.path.basename(x).split('.')[0], test_generator.filepaths)\n",
    "\n",
    "df = pd.DataFrame(output, index=fids, columns=train_generator.class_indices)\n",
    "df.index.name = 'id'\n",
    "\n",
    "submission_format = pd.read_csv(Path(OUTPUT_DIR, 'submission_format.csv'), index_col='id')\n",
    "df = df.reindex(submission_format.index)\n",
    "df.to_csv(Path(OUTPUT_DIR, \"resnet-submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dd-sub-valid output/submission_format.csv output/resnet-submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "model = InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "# model.summary()\n",
    "top_model = Sequential([\n",
    "    Flatten(input_shape=model.output_shape[1:]),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "seq = Sequential([model, top_model])\n",
    "# Compile with Binary Crossentropy loss and SGD optimizer\n",
    "seq.compile(loss='categorical_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.9), metrics=['accuracy'])\n",
    "# Train for 5 epochs\n",
    "seq.fit_generator(train_generator, epochs=5, validation_data=valid_generator)\n",
    "\n",
    "output = seq.predict_generator(test_generator)\n",
    "fids = map(lambda x: os.path.basename(x).split('.')[0], test_generator.filepaths)\n",
    "\n",
    "df = pd.DataFrame(output, index=fids, columns=train_generator.class_indices)\n",
    "df.index.name = 'id'\n",
    "\n",
    "submission_format = pd.read_csv(Path(OUTPUT_DIR, 'submission_format.csv'), index_col='id')\n",
    "df = df.reindex(submission_format.index)\n",
    "df.to_csv(Path(OUTPUT_DIR, \"inception-submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dd-sub-valid output/submission_format.csv output/inception-submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "model = VGG19(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "# model.summary()\n",
    "top_model = Sequential([\n",
    "    Flatten(input_shape=model.output_shape[1:]),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "seq = Sequential([model, top_model])\n",
    "# Compile with Binary Crossentropy loss and SGD optimizer\n",
    "seq.compile(loss='categorical_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.9), metrics=['accuracy'])\n",
    "# Train for 5 epochs\n",
    "seq.fit_generator(train_generator, epochs=5, validation_data=valid_generator)\n",
    "\n",
    "output = seq.predict_generator(test_generator)\n",
    "fids = map(lambda x: os.path.basename(x).split('.')[0], test_generator.filepaths)\n",
    "\n",
    "df = pd.DataFrame(output, index=fids, columns=train_generator.class_indices)\n",
    "df.index.name = 'id'\n",
    "\n",
    "submission_format = pd.read_csv(Path(OUTPUT_DIR, 'submission_format.csv'), index_col='id')\n",
    "df = df.reindex(submission_format.index)\n",
    "df.to_csv(Path(OUTPUT_DIR, \"vgg19-submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dd-sub-valid output/submission_format.csv output/vgg19-submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET15V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "model =  ResNet152V2(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "# model.summary()\n",
    "top_model = Sequential([\n",
    "    Flatten(input_shape=model.output_shape[1:]),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "seq = Sequential([model, top_model])\n",
    "# Compile with Binary Crossentropy loss and SGD optimizer\n",
    "seq.compile(loss='categorical_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.9), metrics=['accuracy'])\n",
    "# Train for 5 epochs\n",
    "seq.fit_generator(train_generator, epochs=5, validation_data=valid_generator)\n",
    "\n",
    "output = seq.predict_generator(test_generator)\n",
    "fids = map(lambda x: os.path.basename(x).split('.')[0], test_generator.filepaths)\n",
    "\n",
    "df = pd.DataFrame(output, index=fids, columns=train_generator.class_indices)\n",
    "df.index.name = 'id'\n",
    "\n",
    "submission_format = pd.read_csv(Path(OUTPUT_DIR, 'submission_format.csv'), index_col='id')\n",
    "df = df.reindex(submission_format.index)\n",
    "df.to_csv(Path(OUTPUT_DIR, \"resnet15v2-submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dd-sub-valid output/submission_format.csv output/resnet15v2-submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "model = Xception(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "# model.summary()\n",
    "top_model = Sequential([\n",
    "    Flatten(input_shape=model.output_shape[1:]),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "seq = Sequential([model, top_model])\n",
    "# Compile with Binary Crossentropy loss and SGD optimizer\n",
    "seq.compile(loss='categorical_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.9), metrics=['accuracy'])\n",
    "# Train for 5 epochs\n",
    "seq.fit_generator(train_generator, epochs=5, validation_data=valid_generator)\n",
    "\n",
    "output = seq.predict_generator(test_generator)\n",
    "fids = map(lambda x: os.path.basename(x).split('.')[0], test_generator.filepaths)\n",
    "\n",
    "df = pd.DataFrame(output, index=fids, columns=train_generator.class_indices)\n",
    "df.index.name = 'id'\n",
    "\n",
    "submission_format = pd.read_csv(Path(OUTPUT_DIR, 'submission_format.csv'), index_col='id')\n",
    "df = df.reindex(submission_format.index)\n",
    "df.to_csv(Path(OUTPUT_DIR, \"xception-submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dd-sub-valid output/submission_format.csv output/xception-submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
